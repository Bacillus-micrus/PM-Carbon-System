---
title: "Ocean acidification in the continental margin of Portugal: filling gaps with old data"
author: "Nils Lucas Jacobsen, Marcos Fontela"
date: "`r format(Sys.time(), '%d %B, %Y')`"  # With Sys.Date it updates automatically
output: 
  html_document:
    toc: yes
    toc_float: yes
    toc_depth: 5
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.align = "center")

# This step installs packages if needed
list.of.packages <- c("R.matlab", "rlist", "tidyverse", "readxl", "marmap", "rgdal", "raster", "seacarb", "xlsx", "reshape2", "readr", "lubridate", "stargazer")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

# Load packages
library(R.matlab)
library(rlist)
library(marmap)
library(rgdal)
library(raster)
library(tidyverse)
library(readxl)
library(seacarb)
library(xlsx)
library(reshape2)
library(readr)
library(lubridate)
library(stargazer)
```

# PM trends step 1 - Preparation, carbon computations, and preliminary analysis
```{r Loading and filtering data & defining study area}

A <- readMat('GLODAPv2.2020_Atlantic_Ocean.mat')
# Keep the expocodes and their correspondence with G2cruise (expocodeno)
expocodes <- data.frame(); expocodes <- as.data.frame(unlist(A$expocode))
expocodes[, 2] <- as.data.frame(unlist(A$expocodeno))
names(expocodes) <- c("expocode", "expocodeno")
A <- A %>% list.remove(c("expocode", "expocodeno")) %>% as.data.frame()

ABasin <- data.frame(lon = c(-13, -7), lat = c(36, 42))  # Defining the geographical region

# Filter for geographical area, remove NAs in salinity and potential temperature, and add data soucre
A <- A %>%
  filter(G2latitude >= (min(ABasin$lat)) & G2latitude <= (max(ABasin$lat))) %>%
  filter(G2longitude >= (min(ABasin$lon)) & G2longitude <= (max(ABasin$lon))) %>%
  mutate_all(.funs = funs(ifelse(. == "NaN", NA, .))) %>%
  filter((!is.na(G2salinity))) %>%
  filter((!is.na(G2theta))) %>%
  mutate(source = "GLODAP")
```

```{r Layer separation, eval = FALSE, echo = FALSE}

# A <- A %>%
#   mutate(layer = ifelse(G2pressure >= 100 & G2sigma0 <= 27.2, "NACW",
#                       ifelse(G2sigma0 > 27.2 & G2sigma1 <= 32.35,"MW",
#                              ifelse(G2sigma1 > 32.35 & G2sigma2 <= 37, "LSW",
#                                     ifelse(G2sigma2 > 37, "NADW", NA))))) %>%
#   filter(!is.na(layer))  # Delete the NA values in layer (surface points)
# 
# ord <- c("NACW", "MW", "LSW", "NADW")
# A$layer <- factor(A$layer, levels = ord)
```

### Carbon computations
```{r Carbon computations}

A <- A %>%  # Adding flags for seacarb
  mutate(flag = ifelse(G2talkf == 2 & G2tco2f == 2, 15,  # Flag 15 Alk & DIC
                     ifelse(G2talkf == 2 & G2tco2f == 0 & G2phtsinsitutpf == 2, 8,  # Flag 8 pH & Alk
                            ifelse(G2talkf == 0 & G2tco2f == 2 & G2phtsinsitutpf == 2, 9, NA))))  # Flag 9 pH & DIC
 
A <- bind_cols(A[, 1:ncol(A)-1],  # To delete the flag column
                     carb(flag = A$flag, 
                          var1 = ifelse(A$flag == 15, A$G2talk / 10^6, 
                                      ifelse(A$flag == 9, A$G2phtsinsitutp,
                                             ifelse(A$flag == 8, A$G2phtsinsitutp, NA))),
                          var2 = ifelse(A$flag == 15, A$G2tco2 / 10^6, 
                                      ifelse(A$flag == 9, A$G2tco2 / 10^6,
                                             ifelse(A$flag == 8, A$G2talk / 10^6, NA))),
                          A$G2salinity, 
                          A$G2theta, 
                          A$G2pressure / 10,  # Pressure in bar!
                          Patm = 1.0, 
                          Pt = A$G2phosphate / 10^6,  # Nutrients in mols/Kg
                          Sit = A$G2silicate / 10^6,
                          pHscale = "T", kf = "pf", k1k2 = "l", ks = "d", b = "u74"))

A <- mutate(A, xcCO3 = CO3 - (CO3 / OmegaAragonite))  # Compute xcCO3

A <- filter(A, !is.na(flag))
```

### Add country & dates
```{r Adding country & dates}

wtf = expocodes[expocodes$expocodeno %in% sort(unique(A$G2cruise)), ]
wtf <- rename(wtf, G2cruise = expocodeno)  # Rename to ease the future join
A <- full_join(A, wtf)
rm(wtf)  # Cleaning

# Adding country with https://vocab.ices.dk/ ICES codes (seen in Olsen 2016, GLODAP paper)
A$country = "Spain"
A$country[A$G2cruise %in% c(25, 58, 64)] = "Germany"
A$country[A$G2cruise %in% c(237)] = "USA"
A$country[A$G2cruise %in% c(368, 392, 393, 394, 395, 1047)] = "France"
A$country[A$G2cruise %in% c(673)] = "Poland"
A$country[A$G2cruise %in% c(679, 683, 693)] = "UK"

A$country = reorder(A$country, A$country, function(x)-length(x))

# Add dates in GLODAP
A <- mutate(A, date = lubridate::ymd(paste(A$G2year, A$G2month, A$G2day, sep = "/")))
```

```{r Various preliminary plots}

  ggplot(A, aes(G2salinity, G2theta, color = as.character(round(G2sigma0, 1)))) +
    geom_point() +
    labs(color = "Sigma0") +
    xlab("Salinity") +
    ylab("Potential Temperature [°C]")

  ggplot(A, aes(x = country)) +
    geom_bar(aes(fill = country)) +
    scale_fill_brewer(type = "qual", palette = "Set1") +
    labs(x = "Country", y = "Number of samples") +
    theme_minimal()
  
  ggplot(A, aes(x = G2year)) +
    geom_histogram(aes(fill = country), alpha = .5) +
    scale_fill_brewer(type = "qual", palette = "Set1") +
    labs(x = "Year", y = "Number of samples") +
    theme_minimal()
  
  A %>%
    filter(G2depth < 500) %>%
    ggplot(., aes(G2year, DIC * 10^6)) + 
    geom_point() + 
    geom_smooth(method = "lm") +
    labs(x = "Year", y = "DIC [μmol/kg]")
  
  A %>%
    filter(G2depth < 500) %>%
    ggplot(., aes(G2year, pH)) + 
    geom_point() + 
    geom_smooth(method = "lm") +
    labs(x = "Year")
```

```{r Adding atmospheric data}

# Annual CO2 from Mauna Loa
url <- 'ftp://ftp.cmdl.noaa.gov/ccg/co2/trends/co2_annmean_mlo.txt'
file  <- tempfile()
download.file(url, file)
CO2 <- read.table(file, header = F)
CO2 <- CO2 %>%
  rename(year = V1, ppm = V2, uncertainty = V3) %>%
  mutate(site = "Mauna Loa") %>%
  dplyr::select(-uncertainty)

CO2 <- rename(CO2, G2year = year)  # To match the name in G2
A <- left_join(A, CO2, by = "G2year")
```

# PM trends step 2 - Trend analysis pH
```{r CO2 data from OldPT and ICES after Neural Networks}

postNN_OldPT <- read_csv("postNN_CO2sys_OldPT.csv", na = "NaN")
postNN_OldPT <- postNN_OldPT %>% 
  mutate(source = "OldPT", country = "Portugal", xcCO3 = CO3out - (CO3out / OmegaARout))

postNN_ICES <- read_csv("postNN_CO2sys_ICESfiltered.csv", na = "NaN")
postNN_ICES <- postNN_ICES %>% 
  mutate(source = "ICES", country = "Portugal", xcCO3 = CO3out - (CO3out / OmegaARout))
```

```{r Computing mean pH with NN data}

only_pH_OldPT <- postNN_OldPT %>%  # A new data.frame from the loaded csv (and we keep it intact as postNN*)
  rename(G2year = year, pH = pHin) %>%  # Same name as in GLODAP
  filter(between(depth, 100, 500)) %>%  # To keep only the samples between 100 m and 500 m (both included)
  filter(pH > 7.9) %>%  # To delete some samples with very low pH (freshwater influence very likely)
  select(G2year, pH, source, country)  # Clean it all
  
# ICES data (The same for the ICES data)
only_pH_ICES <- postNN_ICES %>%
  rename(G2year = year, pH = pHin) %>%  # Same name as in GLODAP
  filter(between(PRESdb, 100, 500)) %>%  # To keep only the samples between 100 m and 500 m (both included)
  filter(pH > 7.9) %>%  # To delete some samples with very low pH (freshwater influence very likely)
  select(G2year, pH, source, country)  # Clean it all

# Again for the GLODAP data
only_pH_G2 <- A %>%
  filter(between(G2depth, 100, 500)) %>%
  select(G2year, pH, source, country)

# Joining the three data.frames
pH_NN <- full_join(only_pH_OldPT, only_pH_ICES)
pH <- full_join(pH_NN, only_pH_G2)  # 2-step join

# Computing the mean pH and error of the mean per year for the whole data set (GLODAP + OldPT + ICES)
final_pH <- pH %>%
  group_by(G2year) %>%
  summarise_at(vars(pH), mean, na.rm = TRUE)

final_pH_error <- pH %>%
  group_by(G2year) %>%
  summarise_at(vars(pH), sd, na.rm = TRUE)

# Computing the mean pH and error of the mean per year for the NN data set (OldPT + ICES)
final_pH_NN <- pH_NN %>%
  group_by(G2year) %>%
  summarise_at(vars(pH), mean, na.rm = TRUE)

final_pH_error_NN <- pH_NN %>%
  group_by(G2year) %>%
  summarise_at(vars(pH), sd, na.rm = TRUE)

# Computing the mean pH and error of the mean per year for the GLODAP data set
final_pH_G2 <- only_pH_G2 %>%
  group_by(G2year) %>%
  summarise_at(vars(pH), mean, na.rm = TRUE)

final_pH_error_G2 <- only_pH_G2 %>%
  group_by(G2year) %>%
  summarise_at(vars(pH), sd, na.rm = TRUE)
```

```{r Linear model for pH}

# Linear model for the complete data set (GLODAP + OldPT + ICES)
RLMmodel_pH <- MASS::rlm(pH ~ G2year, data = final_pH, weights = (1 / final_pH_error$pH))

tableRLMmodel_pH <- summary(RLMmodel_pH)
trend_pH <- tableRLMmodel_pH[["coefficients"]][2, 1]  # This is the rate of change
etrend_pH <- tableRLMmodel_pH[["coefficients"]][2, 2]  # etrend stands for "error in the trend"

pvalue_pH <- pnorm(
  abs(
    broom::tidy(RLMmodel_pH)
    [2, "statistic", drop = TRUE]), lower.tail = FALSE) * 2

# Linear model for the NN data set (OldPT + ICES)
RLMmodel_pH_NN <- MASS::rlm(pH ~ G2year, data = final_pH_NN, weights = (1 / final_pH_error_NN$pH))

tableRLMmodel_pH_NN <- summary(RLMmodel_pH_NN)
trend_pH_NN <- tableRLMmodel_pH_NN[["coefficients"]][2, 1]  # This is the rate of change
etrend_pH_NN <- tableRLMmodel_pH_NN[["coefficients"]][2, 2]  # etrend stands for "error in the trend"

pvalue_pH_NN <- pnorm(
  abs(
    broom::tidy(RLMmodel_pH_NN)
    [2, "statistic", drop = TRUE]), lower.tail = FALSE) * 2

# Linear model for the GLODAP data set
RLMmodel_pH_G2 <- MASS::rlm(pH ~ G2year, data = final_pH_G2, weights = (1 / final_pH_error_G2$pH))

tableRLMmodel_pH_G2 <- summary(RLMmodel_pH_G2)
trend_pH_G2 <- tableRLMmodel_pH_G2[["coefficients"]][2, 1]  # This is the rate of change
etrend_pH_G2 <- tableRLMmodel_pH_G2[["coefficients"]][2, 2]  # etrend stands for "error in the trend"

pvalue_pH_G2 <- pnorm(
  abs(
    broom::tidy(RLMmodel_pH_G2)
    [2, "statistic", drop = TRUE]), lower.tail = FALSE) * 2
```

Method: The data-set used for the pH analysis consists of the combined data taken from GLODAP, ICES, as well as the "rescued" data from the old cruises in the Portuguese Margin. pH is represented on the total scale and at in situ temperature and pressure. Very low pH-values below 7.9 were excluded, since freshwater influence is very likely in those cases. As before, only data points below 100 m, in order to avoid seasonal variation, and above 500 m, due to sample constraint in the OldPT data set, were included in the study. Mean pH and standard deviation per year were computed for the complete data set (GLODAP, ICES, and OldPT), GLODAP data alone, and for the modelled data (ICES and OldPT). Using these means and standard deviations, we applied a robust linear model, with the "rlm" function from the R package "MASS", to compute the pH trends, as well as the error of the trends. The associated p-values were computed with the "pnorm" function. 
```{r Plot trend pH}

ggplot(final_pH, aes(G2year, pH)) +
  geom_jitter(data = pH, aes(colour = source), alpha = .7, shape = 4, size = .3) +
  geom_smooth(method = MASS::rlm, color = "red", size = 2) +
  geom_point() +
  theme_minimal() +
  xlab("Year")
```
Result: Figure 3 shows the pH trend between 1971 and 2016 in subsurface waters (100 m - 500 m) of the Portuguese Margin. The measurements are coloured according to their source, GLODAP in red, ICES in green, and old cruise data in blue. The black points represent the means of each year. [Should I add the min and max value of the trend? If yes, how can I find them?] The pH value decreased steadily at a rate of -0.0017 ± 0.0002 per year. The associated p-value is < 0.05. Through adding the pH values from the "rescued" old cruise data, we were able to fill knowledge gaps and increase the time frame of the linear model by about one decade.
Using only the data from GLODAP, a negative trend of -0.0012 ± 0.0002 was computed (p-value < 0.05). For the neural network data the trend was -0.0017 ± 0.0009 with a p-value < 0.05.

# PM trends step 3 - Trend analysis anthropogenic carbon
```{r Computing mean Cant per year}

Cant <- read.csv("Cant_source.csv")

Cant$source[Cant$source == "PT"] = "OldPT"
Cant$source[Cant$source == "G2"] = "GLODAP"
Cant$source[Cant$source == "IC"] = "ICES"

only_Cant <- Cant %>% 
  filter(latitude >= (min(ABasin$lat)) & latitude <= (max(ABasin$lat))) %>%
  filter(longitude >= (min(ABasin$lon)) & longitude <= (max(ABasin$lon))) %>%
  mutate_all(.funs = funs(ifelse(. == "NaN", NA, .))) %>%
  filter(between(Depth, 100, 500)) %>%
  filter(!is.na(cAntPhiCt0ML)) %>%
  select(year, cAntPhiCt0ML, source)

##### need to rename the variables #####
# colnames(only_Cant$source)[colnames(only_Cant$source) == "G2"] <- "GLODAP"

# complete data set
final_Cant <- only_Cant %>%
  group_by(year) %>%
  summarise_at(vars(cAntPhiCt0ML), mean, na.rm = TRUE)

final_Cant_error <- only_Cant %>%
  group_by(year) %>%
  summarise_at(vars(cAntPhiCt0ML), sd, na.rm = TRUE)

# Neural network data
final_Cant_NN <- only_Cant %>%
  filter(source == "OldPT" | source == "ICES") %>%
  group_by(year) %>%
  summarise_at(vars(cAntPhiCt0ML), mean, na.rm = TRUE)

final_Cant_error_NN <- only_Cant %>%
  filter(source == "OldPT" | source == "ICES") %>%
  group_by(year) %>%
  summarise_at(vars(cAntPhiCt0ML), sd, na.rm = TRUE)

# GLODAP data
final_Cant_G2 <- only_Cant %>%
  filter(source == "GLODAP") %>%
  group_by(year) %>%
  summarise_at(vars(cAntPhiCt0ML), mean, na.rm = TRUE)

final_Cant_error_G2 <- only_Cant %>%
  filter(source == "GLODAP") %>%
  group_by(year) %>%
  summarise_at(vars(cAntPhiCt0ML), sd, na.rm = TRUE)
```

```{r Linear model for Cant}

# Complete data set
RLMmodel_Cant <- MASS::rlm(cAntPhiCt0ML ~ year, data = final_Cant, weights = (1 / final_Cant_error$cAntPhiCt0ML))

tableRLMmodel_Cant <- summary(RLMmodel_Cant)
trend_Cant <- tableRLMmodel_Cant[["coefficients"]][2, 1]  # This is the rate of change
etrend_Cant <- tableRLMmodel_Cant[["coefficients"]][2, 2]  # etrend stands for "error in the trend"

pvalue_Cant <- pnorm(
  abs(
    broom::tidy(RLMmodel_Cant)
    [2, "statistic", drop = TRUE]), lower.tail = FALSE) * 2

# Neural network data
RLMmodel_Cant_NN <- MASS::rlm(cAntPhiCt0ML ~ year, data = final_Cant_NN, weights = (1 / final_Cant_error_NN$cAntPhiCt0ML))

tableRLMmodel_Cant_NN <- summary(RLMmodel_Cant_NN)
trend_Cant_NN <- tableRLMmodel_Cant_NN[["coefficients"]][2, 1]  # This is the rate of change
etrend_Cant_NN <- tableRLMmodel_Cant_NN[["coefficients"]][2, 2]  # etrend stands for "error in the trend"

pvalue_Cant_NN <- pnorm(
  abs(
    broom::tidy(RLMmodel_Cant_NN)
    [2, "statistic", drop = TRUE]), lower.tail = FALSE) * 2

# GLODAP data
RLMmodel_Cant_G2 <- MASS::rlm(cAntPhiCt0ML ~ year, data = final_Cant_G2, weights = (1 / final_Cant_error_G2$cAntPhiCt0ML))

tableRLMmodel_Cant_G2 <- summary(RLMmodel_Cant_G2)
trend_Cant_G2 <- tableRLMmodel_Cant_G2[["coefficients"]][2, 1]  # This is the rate of change
etrend_Cant_G2 <- tableRLMmodel_Cant_G2[["coefficients"]][2, 2]  # etrend stands for "error in the trend"

pvalue_Cant_G2 <- pnorm(
  abs(
    broom::tidy(RLMmodel_Cant_G2)
    [2, "statistic", drop = TRUE]), lower.tail = FALSE) * 2
```

```{r Plot trend Cant}

ggplot(final_Cant, aes(year, cAntPhiCt0ML)) +
  geom_jitter(data = only_Cant, aes(colour = source), alpha = .7, shape = 4, size = .3) +
  geom_smooth(method = MASS::rlm, color = "red", size = 2) +
  geom_point() +
  theme_minimal() +
  xlab("Year") +
  ylab("Anthropogenic carbon [μmol/kg]")
```

# PM trends step 4 - Trend analysis xcCO3
```{r Computing mean xcCO3 per year}

only_xcCO3_G2 <- A %>% 
  filter(between(G2depth, 100, 500)) %>%
  filter(!is.na(xcCO3)) %>%
  select(G2year, xcCO3, source, country) %>%
  mutate(xcCO3 = xcCO3 * 10^6)  # in micromol/kg!

only_xcCO3_OldPT <- postNN_OldPT %>% 
  rename(G2year = year) %>%  # Same name as in GLODAP
  filter(between(depth, 100, 500)) %>%
  filter(!is.na(xcCO3)) %>%
  select(G2year, xcCO3, source, country)

only_xcCO3_ICES <- postNN_ICES %>% 
  rename(G2year = year) %>%  # Same name as in GLODAP
  filter(between(PRESdb, 100, 500)) %>%
  filter(!is.na(xcCO3)) %>%
  select(G2year, xcCO3, source, country)

# Joining the three data.farmes
xcCO3_NN <- full_join(only_xcCO3_OldPT, only_xcCO3_ICES)
xcCO3 <- full_join(xcCO3_NN, only_xcCO3_G2)  # 2-step join

# Computing the mean xcCO3 and error of the mean per year for the whole data set
final_xcCO3 <- xcCO3 %>%
  group_by(G2year) %>%
  summarise_at(vars(xcCO3), mean, na.rm = TRUE)

final_xcCO3_error <- xcCO3 %>%
  group_by(G2year) %>%
  summarise_at(vars(xcCO3), sd, na.rm = TRUE)

# Computing the mean xcCO3 and error of the mean per year for the NN data set
final_xcCO3_NN <- xcCO3_NN %>%
  group_by(G2year) %>%
  summarise_at(vars(xcCO3), mean, na.rm = TRUE)

final_xcCO3_error_NN <- xcCO3_NN %>%
  group_by(G2year) %>%
  summarise_at(vars(xcCO3), sd, na.rm = TRUE)

# Computing the mean xcCO3 and error of the mean per year for the GLODAP data set
final_xcCO3_G2 <- only_xcCO3_G2 %>%
  group_by(G2year) %>%
  summarise_at(vars(xcCO3), mean, na.rm = TRUE)

final_xcCO3_error_G2 <- only_xcCO3_G2 %>%
  group_by(G2year) %>%
  summarise_at(vars(xcCO3), sd, na.rm = TRUE)
```

```{r Linear model for xcCO3}

# Linear model for the whole data set
RLMmodel_xcCO3 <- MASS::rlm(xcCO3 ~ G2year, data = final_xcCO3, weights = (1 / final_xcCO3_error$xcCO3))

tableRLMmodel_xcCo3 <- summary(RLMmodel_xcCO3)
trend_xcCo3 <- tableRLMmodel_xcCo3[["coefficients"]][2, 1]  # This is the rate of change
etrend_xcCo3 <- tableRLMmodel_xcCo3[["coefficients"]][2, 2]  # etrend stands for "error in the trend"

pvalue_xcCO3 <- pnorm(
  abs(
    broom::tidy(RLMmodel_xcCO3)
    [2, "statistic", drop = TRUE]), lower.tail = FALSE) * 2

# Linear model for the NN data set
RLMmodel_xcCO3_NN <- MASS::rlm(xcCO3 ~ G2year, data = final_xcCO3_NN, weights = (1 / final_xcCO3_error_NN$xcCO3))

tableRLMmodel_xcCo3_NN <- summary(RLMmodel_xcCO3_NN)
trend_xcCo3_NN <- tableRLMmodel_xcCo3_NN[["coefficients"]][2, 1]  # This is the rate of change
etrend_xcCo3_NN <- tableRLMmodel_xcCo3_NN[["coefficients"]][2, 2]  # etrend stands for "error in the trend"

pvalue_xcCO3_NN <- pnorm(
  abs(
    broom::tidy(RLMmodel_xcCO3_NN)
    [2, "statistic", drop = TRUE]), lower.tail = FALSE) * 2

# Linear model for the GLODAP data set
RLMmodel_xcCO3_G2 <- MASS::rlm(xcCO3 ~ G2year, data = final_xcCO3_G2, weights = (1 / final_xcCO3_error_G2$xcCO3))

tableRLMmodel_xcCo3_G2 <- summary(RLMmodel_xcCO3_G2)
trend_xcCo3_G2 <- tableRLMmodel_xcCo3_G2[["coefficients"]][2, 1]  # This is the rate of change
etrend_xcCo3_G2 <- tableRLMmodel_xcCo3_G2[["coefficients"]][2, 2]  # etrend stands for "error in the trend"

pvalue_xcCO3_G2 <- pnorm(
  abs(
    broom::tidy(RLMmodel_xcCO3_G2)
    [2, "statistic", drop = TRUE]), lower.tail = FALSE) * 2
```

```{r Plot trend xcCO3}

ggplot(final_xcCO3, aes(G2year, xcCO3)) +
  geom_jitter(data = xcCO3, aes(colour = source), alpha = .7, shape = 4, size = .3) +
  geom_smooth(method = MASS::rlm, color = "red", size = 2) +
  geom_point() +
  theme_minimal() +
  labs(x = "Year", y = "xcCO3 [μmol/kg]")
```

# PM trends step 5 - Plots
```{r Map with stations}

t0 <- Sys.time()

stations <- A %>%
  filter(!is.na(xcCO3)) %>%
  select(G2longitude, G2latitude, G2year) %>%
  distinct(G2longitude, G2latitude, .keep_all = TRUE)

m <- getNOAA.bathy(lon1 = ABasin[1, 1] - 4, lon2 = ABasin[2, 1] + 5,  # -4 and +5 what does it mean?
                     lat1 = ABasin[1, 2] -5 , lat2 = ABasin[2, 2] + 3, resolution = 1)  # 1 is the finest

(basemap <- ggplot(m, aes(x = x, y = y)) +  # when just working with shapes, the map gets really confusing... Should I add colors on top of that or is there a better solution. 22 stations are quite a bit
    coord_quickmap() +
    geom_raster(aes(fill = z)) +
    scale_fill_gradient2(low = "cadetblue1", mid = "white", high = "darkgreen", midpoint = 0, guide = F) +
    geom_contour(aes(z = z), breaks = c(-1000, -2000, -3000, -4000, -5000), colour = "gray", size = 0.5) +
    geom_contour(aes(z = z), breaks = c(0), colour = "black", size = 1) +
    geom_point(data = stations[stations$G2year == 1981, ], aes(x = G2longitude, y = G2latitude),
               size = 3, shape = 1) +
    geom_point(data = stations[stations$G2year == 1982, ], aes(x = G2longitude, y = G2latitude),
               size = 3, shape = 2) +
    geom_point(data = stations[stations$G2year == 1984, ], aes(x = G2longitude, y = G2latitude),
               size = 3, shape = 3) +
    geom_point(data = stations[stations$G2year == 1986, ], aes(x = G2longitude, y = G2latitude),
               size = 3, shape = 4) +
    geom_point(data = stations[stations$G2year == 1988, ], aes(x = G2longitude, y = G2latitude),
               size = 3, shape = 5) +
    geom_point(data = stations[stations$G2year == 1989, ], aes(x = G2longitude, y = G2latitude),
               size = 3, shape = 6) +
    geom_point(data = stations[stations$G2year == 1991, ], aes(x = G2longitude, y = G2latitude),
               size = 3, shape = 7) +
    geom_point(data = stations[stations$G2year == 1993, ], aes(x = G2longitude, y = G2latitude),
               size = 3, shape = 8) +
    geom_point(data = stations[stations$G2year == 1997, ], aes(x = G2longitude, y = G2latitude),
               size = 3, shape = 9) +
    geom_point(data = stations[stations$G2year == 2001, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 10) +
    geom_point(data = stations[stations$G2year == 2002, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 11) +
    geom_point(data = stations[stations$G2year == 2003, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 12) +
    geom_point(data = stations[stations$G2year == 2004, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 13) +
    geom_point(data = stations[stations$G2year == 2005, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 14) +
    geom_point(data = stations[stations$G2year == 2006, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 15) +
    geom_point(data = stations[stations$G2year == 2008, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 16) +
    geom_point(data = stations[stations$G2year == 2010, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 17) +
    geom_point(data = stations[stations$G2year == 2011, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 18) +
    geom_point(data = stations[stations$G2year == 2012, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 19) +
    geom_point(data = stations[stations$G2year == 2013, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 20) +
    geom_point(data = stations[stations$G2year == 2014, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 21) +
    geom_point(data = stations[stations$G2year == 2016, ], aes(x = G2longitude, y = G2latitude), 
               size = 3, shape = 22) +
    scale_shape_manual(values = seq(15, 25)) +  # what does this line do?
    scale_x_continuous(breaks = c(-5, -10, -15), labels = c("5ºW", "10ºW", "15ºW")) +  
    scale_y_continuous(breaks = c(35, 40, 45), labels = c("35ºN", "40ºN", "45ºN")) + 
    labs(x = "", y = "") +
    theme(
      panel.border = element_rect(colour = "black", fill = NA, size = 4),
      text = element_text(size = 28, colour = "black"),
      legend.title = element_blank())
)

savefigure = 0
if (savefigure) {
ggsave(filename = "PMtrends_map.pdf",
       plot = basemap, dpi = 300, width = 20, height = 23, units = "cm")
}

abrirfigura = 0
if (abrirfigura) {
  shell.exec("PMtrends_map.pdf")
}
```

# PM trends step 6 - Tables
```{r Table with trends}

trend_array <- c(trend_pH, trend_Cant, trend_xcCo3)
error_array <- c(etrend_pH, etrend_Cant, etrend_xcCo3)
pvalue_array <- c(pvalue_pH, pvalue_Cant, pvalue_xcCO3)

trend_array_G2 <- c(trend_pH_G2, trend_Cant_G2, trend_xcCo3_G2)
error_array_G2 <- c(etrend_pH_G2, etrend_Cant_G2, etrend_xcCo3_G2)
pvalue_array_G2 <- c(pvalue_pH_G2, pvalue_Cant_G2, pvalue_xcCO3_G2)

trend_array_NN <- c(trend_pH_NN, trend_Cant_NN, trend_xcCo3_NN)
error_array_NN <- c(etrend_pH_NN, etrend_Cant_NN, etrend_xcCo3_NN)
pvalue_array_NN <- c(pvalue_pH_NN, pvalue_Cant_NN, pvalue_xcCO3_NN)

cols <- c("Trend", "Error", "p-value", "Trend", "Error", "p-value", "Trend", "Error", "p-value")
rows <- c("pH", "Cant", "xcCO3")

(trend_matrix <-
  matrix(
    data = c(trend_array, error_array, pvalue_array, trend_array_G2, error_array_G2, pvalue_array_G2, 
             trend_array_NN, error_array_NN, pvalue_array_NN),
    nrow = 3,
    ncol = 9,
    dimnames = list(rows, cols)
  ))
```

